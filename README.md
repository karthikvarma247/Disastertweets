This one of my first NLP project from which I have a learnt a lot.

The Data is taken from one of the kaggle competitions. A small Dataset which allowed me experiment a lot of things

I have played around doing a lot of experiments in feature selection In the beginning I took all the features then I drop one feature which didn't add value and dropped the null values which didn't seem like a nice idea then i created a new for null values.

Data preproccessing step has to be most important step when we deal with anything related to text.

I have tried a few things and I also some of most beautifull kernels on how to preprocess the text but struck with basic preprocessing like removing stops and removing tags and URLs and just kept the basic text.

Then I chose word embedding model to train the data and predict 

Gave me a accuracy of close to 80 percent which isn't bad considering the basic data preproccing and training for 5 epochs


There are many ways to improve model accuracy.

one way was to do Data preproccesing in a better a way.

adding new features like sentiment of the text 

and trying diferent ways of encoding like TFIDF or word2vec
